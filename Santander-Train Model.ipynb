{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO1VDc-Nse7o"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:56:51.788616Z",
     "iopub.status.busy": "2020-06-25T15:56:51.788616Z",
     "iopub.status.idle": "2020-06-25T15:56:51.803618Z",
     "shell.execute_reply": "2020-06-25T15:56:51.802644Z",
     "shell.execute_reply.started": "2020-06-25T15:56:51.788616Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from CustomTokenizer import CustomTokenizer\n",
    "from Accuracy import Accuracy\n",
    "from ModelBuilder import ModelBuilder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "pd.set_option('display.max_colwidth', 600)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Info from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:56:51.805618Z",
     "iopub.status.busy": "2020-06-25T15:56:51.804617Z",
     "iopub.status.idle": "2020-06-25T15:56:51.851616Z",
     "shell.execute_reply": "2020-06-25T15:56:51.850648Z",
     "shell.execute_reply.started": "2020-06-25T15:56:51.805618Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (20104, 4)\n",
      "Test Shape: (6702, 2)\n"
     ]
    }
   ],
   "source": [
    "columns = ['Pregunta', 'Intencion', 'Intencion_cat_label', 'Intencion_encoded']\n",
    "df_train = shuffle(pd.read_csv('data/train_encoded.csv', usecols=columns, sep='|'))\n",
    "df_test = shuffle(pd.read_csv('data/test_santander.csv', usecols=['id','Pregunta']))\n",
    "print('Train Shape: ' + str(df_train.shape))\n",
    "print('Test Shape: ' + str(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:56:51.980619Z",
     "iopub.status.busy": "2020-06-25T15:56:51.979616Z",
     "iopub.status.idle": "2020-06-25T15:56:51.994616Z",
     "shell.execute_reply": "2020-06-25T15:56:51.993644Z",
     "shell.execute_reply.started": "2020-06-25T15:56:51.980619Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_train['Pregunta'].values\n",
    "y = df_train['Intencion_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:56:51.995617Z",
     "iopub.status.busy": "2020-06-25T15:56:51.995617Z",
     "iopub.status.idle": "2020-06-25T15:56:52.010621Z",
     "shell.execute_reply": "2020-06-25T15:56:52.009613Z",
     "shell.execute_reply.started": "2020-06-25T15:56:51.995617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_array = pd.DataFrame(columns=df_train.columns)\n",
    "enableResample = False\n",
    "if enableResample == True:\n",
    "    max_value = df_train['Intencion'].value_counts()[0]\n",
    "    unique_cat = df_train['Intencion'].unique()\n",
    "    for category in list(unique_cat):\n",
    "        df_cat_filter = df_train[df_train['Intencion'] == category]        \n",
    "        if len(df_cat_filter) < max_value:\n",
    "            # upsample minority\n",
    "            df_cat_filter = pd.DataFrame(resample(df_cat_filter, replace=True, # sample with replacement\n",
    "                                     n_samples=max_value # match number in majority class\n",
    "                                    ) # reproducible results\n",
    "                                        )                \n",
    "        df_array = df_array.append(df_cat_filter, ignore_index=True)\n",
    "    # combine majority and upsampled minority      \n",
    "    X = df_array['Pregunta'].values\n",
    "    y = df_array['Intencion_encoded'].values\n",
    "    print(df_array.Intencion.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:56:52.013615Z",
     "iopub.status.busy": "2020-06-25T15:56:52.012614Z",
     "iopub.status.idle": "2020-06-25T15:56:52.042624Z",
     "shell.execute_reply": "2020-06-25T15:56:52.041648Z",
     "shell.execute_reply.started": "2020-06-25T15:56:52.012614Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size = 0.20)\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T15:59:34.914511Z",
     "iopub.status.busy": "2020-06-25T15:59:34.914511Z",
     "iopub.status.idle": "2020-06-25T15:59:34.931524Z",
     "shell.execute_reply": "2020-06-25T15:59:34.930543Z",
     "shell.execute_reply.started": "2020-06-25T15:59:34.914511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Finished Training Model.\n",
      "Best Params for SVC: {'clf__C': 1000, 'clf__gamma': 0.1}\n",
      "\n",
      "--------------------------------------------------------\n",
      "-- Saving Best Parameters for SVC on model_best_params/SVC_best_params.json --\n",
      "--------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------\n",
      "-- Summary --\n",
      "--------------------------------------------------------\n",
      "Training set score for SVC 0.997202\n",
      "Testing  set score for SVC 0.631684\n",
      "--------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------\n",
      "-- Saving model on models/SVC_model.sav --\n",
      "--------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------\n",
      "-- Summary --\n",
      "--------------------------------------------------------\n",
      "balanced_accuracy_score: 0.48\n",
      "\n",
      "--------------------------------------------------------\n",
      "-- Summary --\n",
      "--------------------------------------------------------\n",
      "accuracy_score: 0.63\n"
     ]
    }
   ],
   "source": [
    "modelBuilder = ModelBuilder()\n",
    "optimized_model, model_best_params = modelBuilder.GenerateTrainedModel(classifier, \n",
    "                                                                        X_train, \n",
    "                                                                        X_test, \n",
    "                                                                        y_train, \n",
    "                                                                        y_test)\n",
    "\n",
    "pred = optimized_model.predict(X_test)\n",
    "#Compute the balanced accuracy\n",
    "#The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "#The best value is 1 and the worst value is 0 when adjusted=False.\n",
    "balanced_accuracy_score = Accuracy.get_balanced_accuracy_score(y_test, pred)\n",
    "accuracy_score = Accuracy.get_accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Accuracy on CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>model_best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.631684</td>\n",
       "      <td>0.482126</td>\n",
       "      <td>{'clf__C': 1000, 'clf__gamma': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  accuracy_score  balanced_accuracy_score  \\\n",
       "0        SVC        0.631684                 0.482126   \n",
       "\n",
       "                     model_best_params  \n",
       "0  {'clf__C': 1000, 'clf__gamma': 0.1}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['model_name', 'accuracy_score', 'balanced_accuracy_score', 'model_best_params']\n",
    "data = {\n",
    "    'model_name': classifier.__class__.__name__, \n",
    "    'accuracy_score': accuracy_score, \n",
    "    'balanced_accuracy_score': balanced_accuracy_score, \n",
    "    'model_best_params': [model_best_params]\n",
    "}\n",
    "df_accuracy = pd.DataFrame(data=data,\n",
    "                            columns=columns)\n",
    "ACCURACY_FILENAME = 'data/accuracy.csv'\n",
    "fileexists = os.path.isfile(ACCURACY_FILENAME)\n",
    "header = False\n",
    "mode = 'a'\n",
    "if fileexists == False:\n",
    "    mode='w'\n",
    "    header=True    \n",
    "df_accuracy.to_csv(ACCURACY_FILENAME,mode=mode, header=header, columns=columns, index=False, sep=',')\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-25T16:45:03.207380Z",
     "iopub.status.busy": "2020-06-25T16:45:03.207380Z",
     "iopub.status.idle": "2020-06-25T16:45:03.300359Z",
     "shell.execute_reply": "2020-06-25T16:45:03.299359Z",
     "shell.execute_reply.started": "2020-06-25T16:45:03.207380Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "-- Summary --\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cat_0       0.75      0.69      0.72        13\n",
      "       Cat_1       0.69      0.85      0.76       103\n",
      "      Cat_10       0.00      0.00      0.00         0\n",
      "     Cat_100       0.13      0.33      0.19         6\n",
      "     Cat_101       0.50      0.50      0.50         4\n",
      "     Cat_102       1.00      1.00      1.00         6\n",
      "     Cat_103       0.62      0.40      0.48        20\n",
      "     Cat_105       1.00      1.00      1.00         1\n",
      "     Cat_106       0.75      0.50      0.60        12\n",
      "     Cat_107       1.00      0.83      0.91         6\n",
      "     Cat_108       0.60      0.50      0.55         6\n",
      "     Cat_109       0.33      0.11      0.17         9\n",
      "     Cat_110       0.67      0.67      0.67        15\n",
      "     Cat_112       0.49      0.69      0.57        58\n",
      "     Cat_114       1.00      1.00      1.00         7\n",
      "     Cat_115       0.55      0.44      0.49        27\n",
      "     Cat_117       0.21      0.19      0.20        27\n",
      "     Cat_118       0.80      0.36      0.50        11\n",
      "      Cat_12       0.00      0.00      0.00         0\n",
      "     Cat_120       0.00      0.00      0.00         4\n",
      "     Cat_122       0.50      0.14      0.22         7\n",
      "     Cat_124       0.00      0.00      0.00         4\n",
      "     Cat_125       0.56      0.69      0.62        13\n",
      "     Cat_126       0.50      1.00      0.67         2\n",
      "     Cat_127       0.50      0.29      0.36         7\n",
      "     Cat_128       0.55      1.00      0.71         6\n",
      "     Cat_129       0.49      0.73      0.58        89\n",
      "      Cat_13       1.00      0.50      0.67         2\n",
      "     Cat_130       0.33      0.25      0.29         4\n",
      "     Cat_131       0.20      0.33      0.25         6\n",
      "     Cat_132       0.79      0.91      0.85       128\n",
      "     Cat_133       1.00      0.75      0.86         4\n",
      "     Cat_134       0.00      0.00      0.00         7\n",
      "     Cat_135       0.77      0.71      0.74        14\n",
      "     Cat_136       0.10      0.25      0.14         4\n",
      "     Cat_137       0.75      0.60      0.67         5\n",
      "     Cat_138       0.55      0.79      0.64        61\n",
      "     Cat_139       1.00      0.86      0.92         7\n",
      "      Cat_14       0.00      0.00      0.00         3\n",
      "     Cat_140       1.00      0.71      0.83         7\n",
      "     Cat_141       0.00      0.00      0.00         5\n",
      "     Cat_142       0.00      0.00      0.00         3\n",
      "     Cat_143       1.00      0.86      0.92         7\n",
      "     Cat_144       1.00      0.33      0.50         3\n",
      "     Cat_145       0.40      0.33      0.36         6\n",
      "     Cat_146       0.40      0.29      0.33         7\n",
      "     Cat_147       0.83      0.93      0.88        84\n",
      "     Cat_148       0.80      1.00      0.89         4\n",
      "     Cat_149       1.00      0.67      0.80         3\n",
      "      Cat_15       0.00      0.00      0.00         1\n",
      "     Cat_150       0.50      0.33      0.40         3\n",
      "     Cat_151       0.50      0.50      0.50         6\n",
      "     Cat_152       1.00      1.00      1.00         4\n",
      "     Cat_153       0.33      0.33      0.33         3\n",
      "     Cat_154       1.00      0.75      0.86         4\n",
      "     Cat_155       0.00      0.00      0.00         5\n",
      "     Cat_156       0.50      0.50      0.50         8\n",
      "     Cat_157       0.30      0.25      0.27        12\n",
      "     Cat_158       0.67      0.25      0.36         8\n",
      "     Cat_159       0.30      0.50      0.37         6\n",
      "     Cat_160       0.00      0.00      0.00         1\n",
      "     Cat_161       0.11      0.17      0.13         6\n",
      "     Cat_162       1.00      0.33      0.50         3\n",
      "     Cat_163       0.00      0.00      0.00         3\n",
      "     Cat_164       1.00      1.00      1.00         3\n",
      "     Cat_165       1.00      1.00      1.00         2\n",
      "     Cat_166       0.37      0.59      0.46        22\n",
      "     Cat_167       0.75      0.60      0.67         5\n",
      "     Cat_168       0.00      0.00      0.00         5\n",
      "     Cat_169       0.60      0.60      0.60         5\n",
      "      Cat_17       0.00      0.00      0.00         1\n",
      "     Cat_170       1.00      0.60      0.75         5\n",
      "     Cat_171       0.00      0.00      0.00         1\n",
      "     Cat_172       0.41      0.70      0.52        10\n",
      "     Cat_173       0.38      0.60      0.46         5\n",
      "     Cat_174       0.00      0.00      0.00         0\n",
      "     Cat_175       0.50      0.25      0.33         8\n",
      "     Cat_176       1.00      0.50      0.67         4\n",
      "     Cat_177       1.00      0.33      0.50         6\n",
      "     Cat_178       0.75      0.38      0.50        16\n",
      "     Cat_179       1.00      0.33      0.50         3\n",
      "      Cat_18       0.00      0.00      0.00         1\n",
      "     Cat_180       0.40      0.18      0.25        11\n",
      "     Cat_181       0.25      0.27      0.26        15\n",
      "     Cat_182       0.33      0.25      0.29         4\n",
      "     Cat_183       0.00      0.00      0.00        11\n",
      "     Cat_184       0.00      0.00      0.00         0\n",
      "     Cat_185       0.00      0.00      0.00         3\n",
      "     Cat_186       1.00      0.50      0.67         4\n",
      "     Cat_188       0.50      0.33      0.40         9\n",
      "     Cat_189       1.00      0.67      0.80         3\n",
      "      Cat_19       0.00      0.00      0.00         1\n",
      "     Cat_190       0.86      0.86      0.86         7\n",
      "     Cat_191       0.73      0.73      0.73        11\n",
      "     Cat_192       0.75      0.81      0.78        26\n",
      "     Cat_193       0.78      0.64      0.70        11\n",
      "     Cat_194       1.00      1.00      1.00         5\n",
      "     Cat_195       0.53      0.83      0.65        12\n",
      "     Cat_196       0.00      0.00      0.00         3\n",
      "     Cat_197       0.00      0.00      0.00         4\n",
      "     Cat_198       1.00      0.50      0.67         4\n",
      "     Cat_199       1.00      1.00      1.00         3\n",
      "       Cat_2       0.67      0.67      0.67         3\n",
      "      Cat_20       1.00      1.00      1.00         1\n",
      "     Cat_200       0.70      0.78      0.74         9\n",
      "     Cat_201       0.00      0.00      0.00         1\n",
      "     Cat_202       1.00      0.75      0.86         4\n",
      "     Cat_203       1.00      1.00      1.00         4\n",
      "     Cat_204       0.50      0.50      0.50         2\n",
      "     Cat_206       0.00      0.00      0.00         3\n",
      "     Cat_207       1.00      0.60      0.75         5\n",
      "     Cat_208       1.00      1.00      1.00         1\n",
      "     Cat_209       1.00      1.00      1.00         1\n",
      "     Cat_210       0.75      0.43      0.55         7\n",
      "     Cat_211       0.67      0.55      0.60        11\n",
      "     Cat_212       1.00      0.67      0.80         3\n",
      "     Cat_213       0.00      0.00      0.00         0\n",
      "     Cat_214       1.00      1.00      1.00         3\n",
      "     Cat_215       0.00      0.00      0.00         6\n",
      "     Cat_216       0.75      0.50      0.60         6\n",
      "     Cat_217       0.80      0.67      0.73         6\n",
      "     Cat_218       0.33      0.30      0.32        10\n",
      "     Cat_219       0.82      0.67      0.74        21\n",
      "      Cat_22       0.67      0.50      0.57         4\n",
      "     Cat_220       0.00      0.00      0.00         1\n",
      "     Cat_221       0.67      0.67      0.67         3\n",
      "     Cat_222       0.50      1.00      0.67         2\n",
      "     Cat_223       0.57      0.84      0.68        97\n",
      "     Cat_224       1.00      1.00      1.00         6\n",
      "     Cat_225       0.71      0.85      0.78        75\n",
      "     Cat_226       0.00      0.00      0.00         3\n",
      "     Cat_227       0.00      0.00      0.00         1\n",
      "     Cat_228       0.72      0.89      0.80        47\n",
      "      Cat_23       0.00      0.00      0.00         2\n",
      "     Cat_230       0.00      0.00      0.00         2\n",
      "     Cat_231       0.75      0.86      0.80         7\n",
      "     Cat_232       0.00      0.00      0.00         4\n",
      "     Cat_233       0.75      0.38      0.50         8\n",
      "     Cat_234       1.00      1.00      1.00         1\n",
      "     Cat_236       0.67      0.48      0.56        21\n",
      "     Cat_237       1.00      0.33      0.50         3\n",
      "     Cat_238       1.00      0.20      0.33         5\n",
      "     Cat_239       0.19      0.17      0.18        18\n",
      "      Cat_24       1.00      1.00      1.00         1\n",
      "     Cat_240       0.00      0.00      0.00         3\n",
      "     Cat_241       0.29      0.33      0.31         6\n",
      "     Cat_242       0.83      0.71      0.77         7\n",
      "     Cat_243       0.50      0.56      0.53         9\n",
      "     Cat_244       0.50      0.50      0.50         4\n",
      "     Cat_245       0.57      0.33      0.42        12\n",
      "     Cat_246       0.89      0.42      0.57        19\n",
      "     Cat_247       0.40      0.40      0.40         5\n",
      "     Cat_248       0.63      0.85      0.72        85\n",
      "     Cat_249       0.73      0.44      0.55        18\n",
      "      Cat_25       0.00      0.00      0.00         1\n",
      "     Cat_250       0.67      0.67      0.67         3\n",
      "     Cat_251       0.73      0.88      0.80        80\n",
      "     Cat_252       0.00      0.00      0.00         0\n",
      "     Cat_254       0.38      0.38      0.38         8\n",
      "     Cat_255       1.00      1.00      1.00         2\n",
      "     Cat_256       0.50      0.20      0.29         5\n",
      "     Cat_257       1.00      0.50      0.67         2\n",
      "     Cat_258       0.64      0.69      0.67        13\n",
      "     Cat_259       1.00      0.50      0.67         2\n",
      "      Cat_26       1.00      1.00      1.00         2\n",
      "     Cat_260       0.50      0.25      0.33         4\n",
      "     Cat_261       0.67      0.62      0.65        16\n",
      "     Cat_262       0.44      0.29      0.35        14\n",
      "     Cat_263       1.00      0.33      0.50         3\n",
      "     Cat_264       0.36      0.33      0.35        12\n",
      "     Cat_265       0.69      0.78      0.73        72\n",
      "     Cat_266       0.33      0.20      0.25         5\n",
      "     Cat_267       0.29      0.25      0.27         8\n",
      "     Cat_268       1.00      0.44      0.62         9\n",
      "     Cat_269       0.50      0.33      0.40         6\n",
      "      Cat_27       0.80      1.00      0.89         8\n",
      "     Cat_270       0.00      0.00      0.00         7\n",
      "     Cat_271       0.00      0.00      0.00         2\n",
      "     Cat_272       0.25      0.50      0.33         2\n",
      "     Cat_273       0.00      0.00      0.00         4\n",
      "     Cat_274       0.70      0.64      0.67        11\n",
      "     Cat_275       0.33      0.40      0.36        10\n",
      "     Cat_276       1.00      0.29      0.44         7\n",
      "     Cat_277       0.36      0.83      0.50         6\n",
      "     Cat_278       1.00      0.50      0.67         2\n",
      "     Cat_279       0.59      0.45      0.51        29\n",
      "     Cat_280       0.75      0.50      0.60         6\n",
      "     Cat_281       0.00      0.00      0.00         5\n",
      "     Cat_282       0.88      0.70      0.78        10\n",
      "     Cat_283       0.62      0.38      0.48        13\n",
      "     Cat_284       1.00      0.67      0.80         3\n",
      "     Cat_285       1.00      0.50      0.67         2\n",
      "     Cat_286       0.29      0.31      0.30        16\n",
      "     Cat_287       0.74      0.67      0.70        21\n",
      "     Cat_288       0.82      0.78      0.80        85\n",
      "     Cat_289       0.50      0.56      0.53        18\n",
      "      Cat_29       0.17      0.09      0.12        11\n",
      "     Cat_290       0.00      0.00      0.00         9\n",
      "     Cat_291       1.00      1.00      1.00         2\n",
      "     Cat_292       0.25      0.11      0.15        19\n",
      "     Cat_293       0.76      0.86      0.81       113\n",
      "     Cat_294       0.73      0.65      0.69        17\n",
      "     Cat_295       0.00      0.00      0.00         2\n",
      "     Cat_296       1.00      1.00      1.00         1\n",
      "     Cat_297       0.82      0.60      0.69        15\n",
      "     Cat_298       0.33      0.24      0.28        17\n",
      "     Cat_299       0.67      0.21      0.32        19\n",
      "       Cat_3       0.35      0.50      0.41        14\n",
      "      Cat_30       0.50      0.57      0.53         7\n",
      "     Cat_300       0.00      0.00      0.00         3\n",
      "     Cat_301       0.50      0.41      0.45        22\n",
      "     Cat_302       0.64      0.44      0.52        16\n",
      "     Cat_303       0.79      0.96      0.87        80\n",
      "     Cat_304       0.46      0.40      0.43        15\n",
      "     Cat_305       1.00      0.80      0.89         5\n",
      "     Cat_306       1.00      0.91      0.95        11\n",
      "     Cat_307       0.43      0.43      0.43         7\n",
      "     Cat_308       0.57      0.40      0.47        10\n",
      "     Cat_309       1.00      0.33      0.50         3\n",
      "      Cat_31       0.60      0.43      0.50        14\n",
      "     Cat_310       0.67      0.50      0.57         4\n",
      "     Cat_311       0.61      0.96      0.75        71\n",
      "     Cat_312       0.52      0.61      0.56        18\n",
      "     Cat_313       1.00      0.50      0.67         8\n",
      "     Cat_314       0.67      0.40      0.50         5\n",
      "     Cat_315       0.50      0.17      0.25         6\n",
      "     Cat_316       0.59      0.87      0.70        60\n",
      "     Cat_317       0.00      0.00      0.00         1\n",
      "     Cat_318       0.33      0.10      0.15        10\n",
      "     Cat_319       0.50      1.00      0.67         1\n",
      "      Cat_32       0.38      0.30      0.33        10\n",
      "     Cat_320       0.58      0.54      0.56        13\n",
      "     Cat_321       1.00      0.75      0.86         4\n",
      "     Cat_322       0.33      0.31      0.32        13\n",
      "     Cat_323       0.20      0.50      0.29         4\n",
      "     Cat_324       1.00      0.33      0.50         3\n",
      "     Cat_325       0.33      0.36      0.35        11\n",
      "     Cat_326       0.19      0.23      0.21        13\n",
      "     Cat_327       0.00      0.00      0.00         1\n",
      "     Cat_328       0.00      0.00      0.00         3\n",
      "     Cat_329       1.00      0.67      0.80         6\n",
      "      Cat_33       0.50      0.33      0.40         3\n",
      "     Cat_330       1.00      0.50      0.67         2\n",
      "     Cat_331       0.67      0.29      0.40         7\n",
      "     Cat_332       0.00      0.00      0.00         5\n",
      "     Cat_333       1.00      0.33      0.50         6\n",
      "     Cat_334       0.57      0.57      0.57         7\n",
      "     Cat_335       0.00      0.00      0.00         4\n",
      "     Cat_336       1.00      1.00      1.00         2\n",
      "     Cat_337       0.84      0.91      0.87        68\n",
      "     Cat_338       0.36      0.29      0.32        17\n",
      "     Cat_339       1.00      0.25      0.40         4\n",
      "      Cat_34       1.00      0.83      0.91         6\n",
      "     Cat_340       0.50      0.57      0.53         7\n",
      "     Cat_341       0.50      0.33      0.40         9\n",
      "     Cat_342       0.81      0.92      0.86        72\n",
      "     Cat_343       1.00      0.60      0.75         5\n",
      "     Cat_344       0.00      0.00      0.00         2\n",
      "     Cat_345       0.40      0.33      0.36        12\n",
      "     Cat_346       0.33      0.18      0.24        11\n",
      "     Cat_347       0.67      0.67      0.67         3\n",
      "     Cat_348       1.00      0.33      0.50         9\n",
      "     Cat_349       0.83      0.83      0.83        12\n",
      "      Cat_35       0.67      0.57      0.62         7\n",
      "     Cat_350       0.75      0.27      0.40        11\n",
      "     Cat_351       0.85      0.92      0.88        12\n",
      "     Cat_352       0.00      0.00      0.00         1\n",
      "     Cat_353       0.43      1.00      0.60         3\n",
      "     Cat_354       0.00      0.00      0.00         1\n",
      "     Cat_355       0.91      0.50      0.65        20\n",
      "     Cat_356       1.00      0.50      0.67         2\n",
      "     Cat_357       1.00      0.70      0.82        10\n",
      "     Cat_358       1.00      1.00      1.00         4\n",
      "     Cat_359       1.00      0.75      0.86        16\n",
      "      Cat_36       0.57      0.31      0.40        26\n",
      "      Cat_37       0.33      0.33      0.33         3\n",
      "      Cat_38       0.83      0.45      0.59        11\n",
      "      Cat_39       0.81      0.93      0.87        91\n",
      "       Cat_4       0.00      0.00      0.00         2\n",
      "      Cat_40       0.50      0.10      0.17        10\n",
      "      Cat_41       0.82      0.85      0.84        72\n",
      "      Cat_42       0.83      1.00      0.91         5\n",
      "      Cat_43       0.00      0.00      0.00         3\n",
      "      Cat_44       0.82      0.64      0.72        14\n",
      "      Cat_45       0.33      0.50      0.40         4\n",
      "      Cat_46       1.00      0.25      0.40         4\n",
      "      Cat_47       1.00      0.67      0.80         3\n",
      "      Cat_48       0.67      0.67      0.67         6\n",
      "      Cat_49       0.67      0.57      0.62         7\n",
      "       Cat_5       0.69      0.60      0.64        15\n",
      "      Cat_50       0.61      0.35      0.45        31\n",
      "      Cat_51       1.00      0.43      0.60         7\n",
      "      Cat_52       1.00      0.25      0.40         4\n",
      "      Cat_53       0.00      0.00      0.00         2\n",
      "      Cat_54       1.00      0.67      0.80         3\n",
      "      Cat_55       0.67      1.00      0.80         2\n",
      "      Cat_56       0.70      0.70      0.70        20\n",
      "      Cat_57       0.91      0.83      0.87        12\n",
      "      Cat_58       1.00      0.67      0.80         3\n",
      "      Cat_59       1.00      1.00      1.00         1\n",
      "       Cat_6       0.00      0.00      0.00         1\n",
      "      Cat_60       0.50      1.00      0.67         1\n",
      "      Cat_61       0.38      0.23      0.29        13\n",
      "      Cat_62       0.25      0.33      0.29         3\n",
      "      Cat_63       0.67      0.50      0.57         4\n",
      "      Cat_64       1.00      0.60      0.75         5\n",
      "      Cat_65       0.58      0.58      0.58        12\n",
      "      Cat_66       0.00      0.00      0.00         1\n",
      "      Cat_67       0.67      0.67      0.67         3\n",
      "      Cat_68       0.60      0.50      0.55         6\n",
      "      Cat_69       0.83      0.71      0.77         7\n",
      "       Cat_7       1.00      1.00      1.00         1\n",
      "      Cat_70       0.83      1.00      0.91         5\n",
      "      Cat_72       0.33      0.20      0.25         5\n",
      "      Cat_73       0.56      0.71      0.63         7\n",
      "      Cat_74       0.00      0.00      0.00         5\n",
      "      Cat_75       0.33      0.25      0.29         4\n",
      "      Cat_76       0.67      0.67      0.67         3\n",
      "      Cat_77       0.33      0.09      0.14        11\n",
      "      Cat_78       0.67      0.67      0.67         3\n",
      "      Cat_79       0.20      0.25      0.22         4\n",
      "       Cat_8       1.00      1.00      1.00         1\n",
      "      Cat_80       0.17      0.17      0.17        12\n",
      "      Cat_81       0.75      1.00      0.86         3\n",
      "      Cat_82       0.12      0.20      0.15         5\n",
      "      Cat_83       0.50      0.50      0.50        18\n",
      "      Cat_84       0.67      0.67      0.67         3\n",
      "      Cat_85       0.67      0.25      0.36         8\n",
      "      Cat_86       0.00      0.00      0.00         7\n",
      "      Cat_87       0.12      0.20      0.15         5\n",
      "      Cat_88       0.75      0.75      0.75         4\n",
      "      Cat_89       0.25      0.50      0.33         2\n",
      "       Cat_9       0.00      0.00      0.00         3\n",
      "      Cat_90       0.33      0.25      0.29         4\n",
      "      Cat_91       0.62      0.25      0.36        20\n",
      "      Cat_92       0.75      0.38      0.50         8\n",
      "      Cat_93       0.33      0.36      0.35        11\n",
      "      Cat_94       1.00      0.50      0.67         2\n",
      "      Cat_95       1.00      1.00      1.00         3\n",
      "      Cat_96       0.76      0.86      0.81        63\n",
      "      Cat_97       0.78      0.54      0.64        13\n",
      "      Cat_98       0.50      0.29      0.36         7\n",
      "      Cat_99       0.50      0.33      0.40        18\n",
      "\n",
      "    accuracy                           0.63      4021\n",
      "   macro avg       0.56      0.47      0.49      4021\n",
      "weighted avg       0.63      0.63      0.61      4021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()        \n",
    "encoder.fit(df_train['Intencion'])    \n",
    "y_test_labels = encoder.inverse_transform(y_test)\n",
    "pred_labels = list(encoder.inverse_transform(pred))\n",
    "report = Accuracy.get_classification_report(y_test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predicted test to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>Intencion</th>\n",
       "      <th>Intencion_cat_label</th>\n",
       "      <th>Intencion_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>6461</td>\n",
       "      <td>quiero liquidar una posición en bonos</td>\n",
       "      <td>66</td>\n",
       "      <td>Cat_163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>siguen enviando resumen de deuda cuando ya di de baja la tarjeta</td>\n",
       "      <td>15</td>\n",
       "      <td>Cat_112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1827</td>\n",
       "      <td>darle alto tarjeta</td>\n",
       "      <td>257</td>\n",
       "      <td>Cat_337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                          Pregunta  \\\n",
       "6461  6461                             quiero liquidar una posición en bonos   \n",
       "102    102  siguen enviando resumen de deuda cuando ya di de baja la tarjeta   \n",
       "1827  1827                                                darle alto tarjeta   \n",
       "\n",
       "      Intencion Intencion_cat_label Intencion_cat  \n",
       "6461         66             Cat_163           163  \n",
       "102          15             Cat_112           112  \n",
       "1827        257             Cat_337           337  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_det = optimized_model.predict(df_test['Pregunta'])\n",
    "df_test['Intencion'] = pred_det\n",
    "\n",
    "df_test['Intencion_cat_label'] = encoder.inverse_transform(df_test['Intencion'])\n",
    "df_test['Intencion_cat'] = df_test['Intencion_cat_label'].str[4:]\n",
    "SUBMIT_FILE = 'data/submit_{}.csv'.format(classifier.__class__.__name__)\n",
    "df_test.to_csv(SUBMIT_FILE,mode='w', header=False, columns=['id','Intencion_cat'], index=False, sep=',')\n",
    "\n",
    "df_test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('data-science': conda)",
   "language": "python",
   "name": "python37664bitdatascienceconda1f57879554394e3fa4d3e34eec580a38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
