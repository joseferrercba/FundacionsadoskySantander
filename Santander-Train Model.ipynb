{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO1VDc-Nse7o"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.268344Z",
     "iopub.status.busy": "2020-07-11T13:14:18.268344Z",
     "iopub.status.idle": "2020-07-11T13:14:18.283359Z",
     "shell.execute_reply": "2020-07-11T13:14:18.282375Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.268344Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from classes.CustomTokenizer import CustomTokenizer\n",
    "from classes.Accuracy import Accuracy\n",
    "from classes.ModelBuilder import ModelBuilder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "pd.set_option('display.max_colwidth', 600)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.285348Z",
     "iopub.status.busy": "2020-07-11T13:14:18.285348Z",
     "iopub.status.idle": "2020-07-11T13:14:18.300364Z",
     "shell.execute_reply": "2020-07-11T13:14:18.298435Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.285348Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.302351Z",
     "iopub.status.busy": "2020-07-11T13:14:18.301343Z",
     "iopub.status.idle": "2020-07-11T13:14:18.315154Z",
     "shell.execute_reply": "2020-07-11T13:14:18.314162Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.302351Z"
    }
   },
   "outputs": [],
   "source": [
    "labelEncoders = dict()\n",
    "def labelEncoder(df, column, params = {}):    \n",
    "    le = preprocessing.LabelEncoder()        \n",
    "    le.fit(df[column])    \n",
    "    column_encoded = le.transform(df[column])\n",
    "    labelEncoders[column] = le\n",
    "    return column_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Info from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.317153Z",
     "iopub.status.busy": "2020-07-11T13:14:18.317153Z",
     "iopub.status.idle": "2020-07-11T13:14:18.395149Z",
     "shell.execute_reply": "2020-07-11T13:14:18.394174Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.317153Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train Shape: (20104, 5)\nTest Shape: (6702, 2)\n"
    }
   ],
   "source": [
    "columns = ['Pregunta', 'Intencion']\n",
    "df_train = shuffle(pd.read_csv('data/train.csv', usecols=columns, sep='|'))\n",
    "df_test = shuffle(pd.read_csv('data/test_santander.csv', usecols=['id','Pregunta']))\n",
    "\n",
    "df_train['Intencion_cat_label'] = df_train['Intencion'].str[4:]\n",
    "df_train['Intencion_cat_label'] = df_train['Intencion_cat_label'].astype('int32')\n",
    "df_train['Intencion_encoded'] = labelEncoder(df_train, 'Intencion')\n",
    "#df_train['Pregunta_encoded'] = labelEncoder(df_train, 'Pregunta')\n",
    "\n",
    "print('Train Shape: ' + str(df_train.shape))\n",
    "print('Test Shape: ' + str(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.397151Z",
     "iopub.status.busy": "2020-07-11T13:14:18.397151Z",
     "iopub.status.idle": "2020-07-11T13:14:18.411155Z",
     "shell.execute_reply": "2020-07-11T13:14:18.410152Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.397151Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_train['Pregunta_es'].values\n",
    "y = df_train['Intencion_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.413149Z",
     "iopub.status.busy": "2020-07-11T13:14:18.412149Z",
     "iopub.status.idle": "2020-07-11T13:14:18.426152Z",
     "shell.execute_reply": "2020-07-11T13:14:18.425150Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.413149Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enableResample = False\n",
    "if enableResample == True:\n",
    "    oversample = ADASYN()\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    #max_value = df_train['Intencion'].value_counts()[0]\n",
    "    #unique_cat = df_train['Intencion'].unique()\n",
    "    #for category in list(unique_cat):\n",
    "    #    df_cat_filter = df_train[df_train['Intencion'] == category]        \n",
    "    #    if len(df_cat_filter) < max_value:\n",
    "    #        # upsample minority\n",
    "    #        df_cat_filter = pd.DataFrame(resample(df_cat_filter, replace=True, # sample with replacement\n",
    "    #                                 n_samples=max_value # match number in majority class\n",
    "    #                                ) # reproducible results\n",
    "    #                                    )                \n",
    "    #    df_array = df_array.append(df_cat_filter, ignore_index=True)\n",
    "    ## combine majority and upsampled minority      \n",
    "    #X = df_array['Pregunta'].values\n",
    "    #y = df_array['Intencion_encoded'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.428157Z",
     "iopub.status.busy": "2020-07-11T13:14:18.428157Z",
     "iopub.status.idle": "2020-07-11T13:14:18.441167Z",
     "shell.execute_reply": "2020-07-11T13:14:18.440183Z",
     "shell.execute_reply.started": "2020-07-11T13:14:18.428157Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size = 0.20)\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-11T13:14:18.445176Z",
     "iopub.status.busy": "2020-07-11T13:14:18.444186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Preprocessing data...\nResampling data...\nTraining Model...\nFinished Training Model.\nBest Params for SVC: {'C': 1000, 'gamma': 0.1}\n\n--------------------------------------------------------\n-- Saving Best Parameters for SVC on model_best_params/SVC_best_params.json --\n--------------------------------------------------------\n\n--------------------------------------------------------\n-- Summary --\n--------------------------------------------------------\nTraining set score for SVC 0.983949\nTesting  set score for SVC 0.621238\n--------------------------------------------------------\n\n--------------------------------------------------------\n-- Saving model on models/SVC_model.sav --\n--------------------------------------------------------\n\n--------------------------------------------------------\n-- Summary --\n--------------------------------------------------------\nbalanced_accuracy_score: 0.48\n\n--------------------------------------------------------\n-- Summary --\n--------------------------------------------------------\naccuracy_score: 0.62\n"
    }
   ],
   "source": [
    "modelBuilder = ModelBuilder()\n",
    "optimized_model, model_best_params, X_train, X_test, y_train, y_test = modelBuilder.GenerateTrainedModel(classifier, X_train, X_test, y_train, y_test)\n",
    "\n",
    "pred = optimized_model.predict(X_test)\n",
    "#Compute the balanced accuracy\n",
    "#The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "#The best value is 1 and the worst value is 0 when adjusted=False.\n",
    "balanced_accuracy_score = Accuracy.get_balanced_accuracy_score(y_test, pred)\n",
    "accuracy_score = Accuracy.get_accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Accuracy on CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  model_name  accuracy_score  balanced_accuracy_score  \\\n0        SVC        0.621238                 0.483235   \n\n           model_best_params  \n0  {'C': 1000, 'gamma': 0.1}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>accuracy_score</th>\n      <th>balanced_accuracy_score</th>\n      <th>model_best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVC</td>\n      <td>0.621238</td>\n      <td>0.483235</td>\n      <td>{'C': 1000, 'gamma': 0.1}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "columns = ['model_name', 'accuracy_score', 'balanced_accuracy_score', 'model_best_params']\n",
    "data = {\n",
    "    'model_name': classifier.__class__.__name__, \n",
    "    'accuracy_score': accuracy_score, \n",
    "    'balanced_accuracy_score': balanced_accuracy_score, \n",
    "    'model_best_params': [model_best_params]\n",
    "}\n",
    "df_accuracy = pd.DataFrame(data=data,\n",
    "                            columns=columns)\n",
    "ACCURACY_FILENAME = 'data/accuracy.csv'\n",
    "fileexists = os.path.isfile(ACCURACY_FILENAME)\n",
    "header = False\n",
    "mode = 'a'\n",
    "if fileexists == False:\n",
    "    mode='w'\n",
    "    header=True    \n",
    "df_accuracy.to_csv(ACCURACY_FILENAME,mode=mode, header=header, columns=columns, index=False, sep=',')\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n--------------------------------------------------------\n-- Summary --\n--------------------------------------------------------\n              precision    recall  f1-score   support\n\n       Cat_0       0.78      0.64      0.70        11\n       Cat_1       0.79      0.92      0.85       106\n      Cat_10       0.00      0.00      0.00         2\n     Cat_100       0.43      0.38      0.40         8\n     Cat_101       0.25      0.50      0.33         2\n     Cat_102       1.00      0.91      0.95        11\n     Cat_103       0.44      0.47      0.45        15\n     Cat_105       1.00      1.00      1.00         4\n     Cat_106       0.38      0.50      0.43        10\n     Cat_107       1.00      1.00      1.00         2\n     Cat_108       0.25      0.33      0.29         3\n     Cat_109       0.25      0.17      0.20         6\n      Cat_11       0.00      0.00      0.00         0\n     Cat_110       0.47      0.50      0.48        14\n     Cat_112       0.47      0.49      0.48        57\n     Cat_114       1.00      0.86      0.92         7\n     Cat_115       0.48      0.62      0.55        24\n     Cat_117       0.20      0.16      0.18        19\n     Cat_118       0.62      0.62      0.62         8\n      Cat_12       0.00      0.00      0.00         0\n     Cat_120       0.10      0.25      0.14         4\n     Cat_122       0.67      0.50      0.57         8\n     Cat_124       1.00      1.00      1.00         1\n     Cat_125       0.90      1.00      0.95         9\n     Cat_126       1.00      1.00      1.00         3\n     Cat_127       0.50      1.00      0.67         2\n     Cat_128       0.86      0.60      0.71        10\n     Cat_129       0.54      0.78      0.64        85\n      Cat_13       0.00      0.00      0.00         1\n     Cat_130       1.00      0.50      0.67         2\n     Cat_131       0.33      0.25      0.29         4\n     Cat_132       0.77      0.87      0.82       117\n     Cat_133       0.67      0.67      0.67         3\n     Cat_134       0.29      0.33      0.31         6\n     Cat_135       0.71      0.92      0.80        13\n     Cat_136       0.29      0.67      0.40         3\n     Cat_137       0.25      0.25      0.25         4\n     Cat_138       0.51      0.70      0.59        67\n     Cat_139       1.00      1.00      1.00         3\n      Cat_14       0.00      0.00      0.00         2\n     Cat_140       1.00      1.00      1.00         6\n     Cat_141       0.00      0.00      0.00         3\n     Cat_142       0.00      0.00      0.00         2\n     Cat_143       0.69      0.73      0.71        15\n     Cat_144       0.50      0.50      0.50         4\n     Cat_145       0.00      0.00      0.00         4\n     Cat_146       0.50      0.25      0.33         4\n     Cat_147       0.80      0.87      0.83        99\n     Cat_148       0.29      0.67      0.40         3\n     Cat_149       0.14      0.50      0.22         2\n      Cat_15       0.00      0.00      0.00         1\n     Cat_150       1.00      0.33      0.50         3\n     Cat_151       0.56      0.45      0.50        11\n     Cat_152       0.75      0.60      0.67         5\n     Cat_153       0.25      0.50      0.33         2\n     Cat_154       1.00      0.67      0.80         3\n     Cat_155       0.33      0.33      0.33         3\n     Cat_156       0.62      0.50      0.56        10\n     Cat_157       0.35      0.60      0.44        10\n     Cat_158       0.67      1.00      0.80         6\n     Cat_159       0.25      0.50      0.33         2\n      Cat_16       0.40      1.00      0.57         2\n     Cat_160       1.00      0.20      0.33         5\n     Cat_161       0.20      0.14      0.17         7\n     Cat_162       0.67      0.33      0.44         6\n     Cat_163       0.50      0.67      0.57         3\n     Cat_164       0.50      1.00      0.67         1\n     Cat_165       1.00      1.00      1.00         1\n     Cat_166       0.43      0.41      0.42        22\n     Cat_167       0.60      0.38      0.46         8\n     Cat_168       0.60      0.38      0.46         8\n     Cat_169       0.75      0.43      0.55         7\n      Cat_17       0.12      1.00      0.22         1\n     Cat_170       1.00      1.00      1.00         1\n     Cat_171       0.00      0.00      0.00         4\n     Cat_172       0.71      0.67      0.69        15\n     Cat_173       0.30      0.60      0.40         5\n     Cat_174       0.00      0.00      0.00         3\n     Cat_175       1.00      0.22      0.36        18\n     Cat_176       0.00      0.00      0.00         2\n     Cat_177       1.00      0.29      0.44         7\n     Cat_178       0.54      0.54      0.54        13\n     Cat_179       1.00      0.33      0.50         6\n      Cat_18       0.06      1.00      0.12         1\n     Cat_180       0.80      0.50      0.62         8\n     Cat_181       0.30      0.25      0.27        12\n     Cat_182       0.17      0.22      0.19         9\n     Cat_183       0.36      0.29      0.32        14\n     Cat_184       0.00      0.00      0.00         2\n     Cat_185       0.00      0.00      0.00         1\n     Cat_187       0.00      0.00      0.00         3\n     Cat_188       0.43      0.60      0.50         5\n     Cat_189       0.50      1.00      0.67         2\n      Cat_19       1.00      0.50      0.67         2\n     Cat_190       0.33      0.50      0.40         2\n     Cat_191       0.86      0.92      0.89        13\n     Cat_192       0.77      0.77      0.77        31\n     Cat_193       0.90      0.75      0.82        12\n     Cat_194       1.00      0.44      0.62         9\n     Cat_195       0.82      0.82      0.82        11\n     Cat_196       0.29      0.40      0.33         5\n     Cat_197       0.00      0.00      0.00         7\n     Cat_198       0.00      0.00      0.00         1\n     Cat_199       0.00      0.00      0.00         1\n      Cat_20       0.33      0.50      0.40         2\n     Cat_200       0.60      0.50      0.55         6\n     Cat_201       1.00      0.50      0.67         4\n     Cat_202       1.00      1.00      1.00         3\n     Cat_203       1.00      1.00      1.00         4\n     Cat_204       0.00      0.00      0.00         0\n     Cat_205       1.00      1.00      1.00         1\n     Cat_206       0.75      0.75      0.75         4\n     Cat_207       0.50      0.20      0.29         5\n     Cat_208       1.00      1.00      1.00         1\n     Cat_210       0.56      0.56      0.56         9\n     Cat_211       0.75      0.69      0.72        13\n     Cat_212       0.25      0.20      0.22         5\n     Cat_213       0.00      0.00      0.00         1\n     Cat_214       0.83      1.00      0.91         5\n     Cat_215       0.11      0.14      0.12         7\n     Cat_216       0.56      0.83      0.67         6\n     Cat_217       0.67      0.25      0.36         8\n     Cat_218       0.17      0.12      0.14         8\n     Cat_219       0.80      0.55      0.65        22\n      Cat_22       0.33      0.25      0.29         4\n     Cat_220       1.00      0.50      0.67         2\n     Cat_221       1.00      0.33      0.50         3\n     Cat_222       0.00      0.00      0.00         0\n     Cat_223       0.64      0.84      0.73        91\n     Cat_224       0.25      1.00      0.40         1\n     Cat_225       0.61      0.71      0.65        68\n     Cat_226       0.25      0.67      0.36         3\n     Cat_227       1.00      0.25      0.40         4\n     Cat_228       0.75      0.90      0.82        52\n     Cat_229       0.00      0.00      0.00         1\n      Cat_23       0.00      0.00      0.00         1\n     Cat_230       0.00      0.00      0.00         4\n     Cat_231       0.67      0.67      0.67         3\n     Cat_232       0.00      0.00      0.00         1\n     Cat_233       1.00      0.67      0.80         3\n     Cat_234       0.00      0.00      0.00         1\n     Cat_235       0.50      1.00      0.67         1\n     Cat_236       0.67      0.57      0.62        21\n     Cat_237       0.43      0.60      0.50         5\n     Cat_238       1.00      0.29      0.44         7\n     Cat_239       0.21      0.25      0.23        16\n      Cat_24       1.00      1.00      1.00         1\n     Cat_240       0.00      0.00      0.00         1\n     Cat_241       0.44      0.57      0.50         7\n     Cat_242       1.00      0.40      0.57         5\n     Cat_243       0.82      0.75      0.78        12\n     Cat_244       0.40      0.67      0.50         3\n     Cat_245       0.71      0.50      0.59        10\n     Cat_246       0.63      0.60      0.62        20\n     Cat_247       0.25      1.00      0.40         1\n     Cat_248       0.77      0.78      0.77        92\n     Cat_249       0.67      0.86      0.75         7\n      Cat_25       0.00      0.00      0.00         2\n     Cat_250       0.25      1.00      0.40         1\n     Cat_251       0.63      0.83      0.72        76\n     Cat_252       1.00      0.67      0.80         3\n     Cat_254       0.36      0.44      0.40         9\n     Cat_255       1.00      0.20      0.33         5\n     Cat_256       0.00      0.00      0.00         3\n     Cat_257       0.00      0.00      0.00         3\n     Cat_258       0.43      0.33      0.38         9\n     Cat_259       1.00      0.67      0.80         3\n      Cat_26       0.67      0.50      0.57         4\n     Cat_260       0.00      0.00      0.00         4\n     Cat_261       0.53      0.59      0.56        17\n     Cat_262       0.23      0.27      0.25        11\n     Cat_263       1.00      0.29      0.44         7\n     Cat_264       0.62      0.62      0.62        13\n     Cat_265       0.73      0.89      0.80        53\n     Cat_266       0.00      0.00      0.00         5\n     Cat_267       0.40      0.33      0.36        12\n     Cat_268       0.67      0.36      0.47        11\n     Cat_269       0.40      0.50      0.44         4\n      Cat_27       0.67      0.50      0.57         4\n     Cat_270       0.22      0.18      0.20        11\n     Cat_271       0.00      0.00      0.00         3\n     Cat_272       0.00      0.00      0.00         3\n     Cat_273       0.67      0.40      0.50         5\n     Cat_274       0.50      1.00      0.67         4\n     Cat_275       0.67      0.57      0.62         7\n     Cat_276       0.75      0.50      0.60         6\n     Cat_277       0.36      0.57      0.44         7\n     Cat_278       1.00      0.33      0.50         3\n     Cat_279       0.38      0.48      0.43        27\n     Cat_280       1.00      0.44      0.62         9\n     Cat_281       0.33      0.20      0.25         5\n     Cat_282       0.83      0.62      0.71         8\n     Cat_283       0.23      0.38      0.29         8\n     Cat_284       1.00      0.44      0.62         9\n     Cat_285       0.33      1.00      0.50         1\n     Cat_286       0.30      0.43      0.35        14\n     Cat_287       0.56      0.56      0.56        18\n     Cat_288       0.77      0.87      0.82        79\n     Cat_289       0.52      0.55      0.54        20\n      Cat_29       0.71      0.28      0.40        18\n     Cat_290       0.00      0.00      0.00        10\n     Cat_291       1.00      1.00      1.00         2\n     Cat_292       0.33      0.29      0.31        17\n     Cat_293       0.80      0.83      0.81       127\n     Cat_294       0.71      0.59      0.65        17\n     Cat_295       0.22      0.20      0.21        10\n     Cat_296       0.60      1.00      0.75         3\n     Cat_297       0.73      0.57      0.64        14\n     Cat_298       0.21      0.15      0.18        20\n     Cat_299       0.38      0.20      0.26        15\n       Cat_3       0.56      0.56      0.56        18\n      Cat_30       0.88      0.54      0.67        13\n     Cat_300       0.25      0.14      0.18         7\n     Cat_301       0.50      0.41      0.45        17\n     Cat_302       0.33      0.30      0.32        10\n     Cat_303       0.80      0.80      0.80        95\n     Cat_304       0.67      0.38      0.48        16\n     Cat_305       1.00      0.67      0.80         3\n     Cat_306       0.90      1.00      0.95         9\n     Cat_307       0.71      0.71      0.71         7\n     Cat_308       0.50      0.31      0.38        13\n     Cat_309       0.00      0.00      0.00         4\n      Cat_31       0.50      0.29      0.37        17\n     Cat_310       0.40      0.33      0.36         6\n     Cat_311       0.67      0.87      0.76        69\n     Cat_312       0.59      0.45      0.51        22\n     Cat_313       0.71      0.62      0.67         8\n     Cat_314       0.11      0.11      0.11         9\n     Cat_315       1.00      0.50      0.67         6\n     Cat_316       0.56      0.80      0.66        40\n     Cat_317       0.00      0.00      0.00         1\n     Cat_318       0.40      0.25      0.31         8\n     Cat_319       1.00      0.33      0.50         3\n      Cat_32       0.25      0.27      0.26        11\n     Cat_320       0.57      0.89      0.70         9\n     Cat_321       0.00      0.00      0.00         3\n     Cat_322       0.65      0.55      0.59        20\n     Cat_323       0.50      0.33      0.40         9\n     Cat_324       0.33      1.00      0.50         1\n     Cat_325       0.50      0.25      0.33         8\n     Cat_326       0.33      0.19      0.24        16\n     Cat_327       0.00      0.00      0.00         1\n     Cat_328       0.33      0.40      0.36         5\n     Cat_329       1.00      0.62      0.77         8\n      Cat_33       0.50      0.38      0.43         8\n     Cat_330       0.00      0.00      0.00         3\n     Cat_331       0.40      0.40      0.40         5\n     Cat_332       0.60      0.60      0.60         5\n     Cat_333       0.80      0.57      0.67         7\n     Cat_334       1.00      0.25      0.40         4\n     Cat_335       1.00      0.43      0.60         7\n     Cat_336       0.00      0.00      0.00         2\n     Cat_337       0.83      0.78      0.80        58\n     Cat_338       0.71      0.36      0.48        14\n     Cat_339       0.00      0.00      0.00         4\n      Cat_34       0.86      0.86      0.86         7\n     Cat_340       0.40      0.20      0.27        10\n     Cat_341       0.25      0.25      0.25         4\n     Cat_342       0.86      0.89      0.87        70\n     Cat_343       0.00      0.00      0.00         3\n     Cat_344       0.50      0.50      0.50         2\n     Cat_345       0.29      0.55      0.37        11\n     Cat_346       0.40      0.20      0.27        10\n     Cat_347       0.80      1.00      0.89         4\n     Cat_348       1.00      0.25      0.40         4\n     Cat_349       0.69      0.60      0.64        15\n      Cat_35       0.25      0.29      0.27         7\n     Cat_350       0.55      0.52      0.54        21\n     Cat_351       0.38      1.00      0.55         3\n     Cat_352       0.00      0.00      0.00         2\n     Cat_353       0.17      0.33      0.22         3\n     Cat_354       1.00      0.33      0.50         3\n     Cat_355       0.83      0.42      0.56        12\n     Cat_356       0.50      1.00      0.67         1\n     Cat_357       1.00      0.87      0.93        15\n     Cat_358       0.80      0.80      0.80         5\n     Cat_359       1.00      0.69      0.81        16\n      Cat_36       0.35      0.43      0.39        14\n      Cat_37       1.00      0.25      0.40         4\n      Cat_38       0.83      0.42      0.56        12\n      Cat_39       0.89      0.81      0.85       115\n       Cat_4       1.00      0.33      0.50         3\n      Cat_40       1.00      0.67      0.80         3\n      Cat_41       0.89      0.87      0.88        47\n      Cat_42       0.60      0.60      0.60         5\n      Cat_43       0.00      0.00      0.00         1\n      Cat_44       0.67      0.57      0.62         7\n      Cat_45       1.00      0.50      0.67         8\n      Cat_46       0.50      0.33      0.40         3\n      Cat_47       1.00      0.33      0.50         3\n      Cat_48       0.50      0.33      0.40         3\n      Cat_49       0.53      0.64      0.58        14\n       Cat_5       0.40      0.33      0.36         6\n      Cat_50       0.50      0.36      0.42        28\n      Cat_51       0.33      1.00      0.50         1\n      Cat_52       0.00      0.00      0.00         2\n      Cat_53       0.00      0.00      0.00         1\n      Cat_54       0.75      0.75      0.75         4\n      Cat_55       0.00      0.00      0.00         4\n      Cat_56       0.74      0.82      0.78        17\n      Cat_57       1.00      0.53      0.69        17\n      Cat_58       1.00      1.00      1.00         2\n      Cat_59       1.00      0.33      0.50         3\n       Cat_6       0.75      0.50      0.60         6\n      Cat_60       0.75      0.75      0.75         4\n      Cat_61       0.38      0.40      0.39        15\n      Cat_62       0.00      0.00      0.00         5\n      Cat_63       0.50      0.29      0.36         7\n      Cat_64       1.00      0.17      0.29         6\n      Cat_65       0.67      0.50      0.57         8\n      Cat_66       0.00      0.00      0.00         3\n      Cat_67       0.40      0.40      0.40         5\n      Cat_68       1.00      1.00      1.00         5\n      Cat_69       0.60      0.86      0.71         7\n       Cat_7       1.00      0.67      0.80         3\n      Cat_70       1.00      0.50      0.67         4\n      Cat_71       1.00      0.75      0.86         4\n      Cat_72       0.17      0.10      0.12        10\n      Cat_73       0.18      0.33      0.24         6\n      Cat_74       0.00      0.00      0.00         4\n      Cat_75       0.33      0.50      0.40         2\n      Cat_76       1.00      0.75      0.86         4\n      Cat_77       0.29      0.29      0.29         7\n      Cat_78       0.50      0.67      0.57         3\n      Cat_79       0.33      0.33      0.33         3\n      Cat_80       0.25      0.12      0.16        17\n      Cat_81       0.80      0.50      0.62         8\n      Cat_82       0.33      0.50      0.40         4\n      Cat_83       0.67      0.61      0.64        23\n      Cat_84       0.33      0.25      0.29         4\n      Cat_85       1.00      0.50      0.67         6\n      Cat_86       0.22      0.22      0.22         9\n      Cat_87       0.20      0.20      0.20         5\n      Cat_88       0.67      0.50      0.57         4\n      Cat_89       0.75      0.60      0.67         5\n       Cat_9       1.00      0.75      0.86         4\n      Cat_90       0.67      0.22      0.33         9\n      Cat_91       0.46      0.73      0.56        15\n      Cat_92       0.80      0.57      0.67         7\n      Cat_93       0.25      0.25      0.25        12\n      Cat_94       1.00      0.75      0.86         4\n      Cat_95       1.00      0.60      0.75         5\n      Cat_96       0.85      0.96      0.90        74\n      Cat_97       0.56      0.62      0.59        16\n      Cat_98       0.60      0.43      0.50        14\n      Cat_99       0.29      0.29      0.29        17\n\n    accuracy                           0.62      4021\n   macro avg       0.53      0.48      0.47      4021\nweighted avg       0.64      0.62      0.61      4021\n\n"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()        \n",
    "encoder.fit(df_train['Intencion'])    \n",
    "y_test_labels = encoder.inverse_transform(y_test)\n",
    "pred_labels = list(encoder.inverse_transform(pred))\n",
    "report = Accuracy.get_classification_report(y_test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predicted test to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'necesitaba un solo cbu para mis cuentas en pesos y dolares'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a98dae894df0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_det\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimized_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pregunta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Intencion'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_det\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Intencion_cat_label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Intencion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Intencion_cat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Intencion_cat_label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[1;32m--> 466\u001b[1;33m                             order=\"C\", accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'necesitaba un solo cbu para mis cuentas en pesos y dolares'"
     ]
    }
   ],
   "source": [
    "pred_det = optimized_model.predict(df_test['Pregunta'])\n",
    "df_test['Intencion'] = pred_det\n",
    "\n",
    "df_test['Intencion_cat_label'] = encoder.inverse_transform(df_test['Intencion'])\n",
    "df_test['Intencion_cat'] = df_test['Intencion_cat_label'].str[4:]\n",
    "SUBMIT_FILE = 'data/submit_{}.csv'.format(classifier.__class__.__name__)\n",
    "df_test.to_csv(SUBMIT_FILE,mode='w', header=False, columns=['id','Intencion_cat'], index=False, sep=',')\n",
    "\n",
    "df_test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bit7a7b2bda34524aebab0a9e4b2947329a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}